import pymysql
import pymysql
import datetime
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
import time

class MysqlDB:
    def __init__(self, host='localhost', user='root', password='', db='',charset='utf8'):
        self.conn = pymysql.connect(
            host=host,
            user=user,
            password=password,
            db=db,
            charset=charset
        )
        self.cursor = self.conn.cursor()

    def __del__(self):
        self.conn.commit()
        self.conn.close()

    def getDataFromTable(self, table):
        SQL = 'SELECT *FROM`%s`' %(table)
        self.cursor.execute(SQL)
        return self.cursor.fetchall()

    def insertIntoNews(self, news_title, news_link):
        SQL = "INSERT INTO `news`(`news_title`, `news_link`) VALUES ('%s', '%s')" %(news_title, news_link)

        self.cursor.execute(SQL)

    def insertIntoComments(self, description, comment_like, comment_unlike, news_idx):
        SQL = "INSERT INTO `comments`(`descripton`, `comment_like`, `comment_unlike`, `news_idx`) VALUES ('%s', '%d', '%d', '%d')" %(description, comment_like, comment_unlike, news_idx )

        self.cursor.execute(SQL)


    def deleteFromNews(self):
        SQL = "DELETE FROM `news` WHERE `news_idx`"


class NaverNewsCrawler:

    def __init__(self,src):
        self.driver = webdriver.Chrome(src)
        self.driver.get('https://www.google.com')
        self.driver.implicitly_wait(3)

    def get_top30_news(self, date):
        rootURI= 'https://news.naver.com/main/ranking/popularDay.nhn?rankingType=popular_day&sectionId=103&date='

        self.driver.get(rootURI+date)
        time.sleep(2)

        data = []

        items = self.driver.find_elements_by_css_selector('li.ranking_item')

        for item in items:
            news = {
                'news_title':'',
                'news_link':''
            }

            a = item.find_element_by_css_selector('div.ranking_headline a')

            news['news_title'] = a.text.replace("'",'"')
            news['news_link'] = a.get_attribute('href')

            data.append(news)


        return data

    def get_comments_from_news(self, link, news_idx):
        self.driver.get(link)
        time.sleep(2)

        data = []
        items = self.driver.find_elements_by_css_selector('li.u_cbox_comment')

        for item in items:
            comment = {
                'description' : '',
                'comment_link':0,
                'comment_unlike':0,
                'news_idx':news_idx,
            }

            comment[]

    def __del__(self):
        self.driver.close()


DB = MysqlDB(user='id', password='password', db='db')

Crawler = NaverNewsCrawler('chromedriver path')
top30_news = Crawler.get_top30_news('20180807')

for news in top30_news:
    DB.insertIntoNews( news.get('news_title'), news.get('news_link') )
